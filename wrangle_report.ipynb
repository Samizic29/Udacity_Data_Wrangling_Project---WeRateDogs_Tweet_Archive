{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wrangle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this section, three pieces of data were gathered for the project using different methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset was download and import using pandas csv:\n",
    "- Import pandas as pd.\n",
    "- Read the data (csv) to a dataframe `tweets_archive` using `read_csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second dataset uses Request library to download the tweet image prediction (image_prediction.tsv):\n",
    "- Import the request library.\n",
    "- Create a file name to read the response content.\n",
    "- Assign the url to get reponse for the request.\n",
    "- Use open file method and write the response content to the file name created.\n",
    "- Read the data (tsv) to a dataframe `tweets_image` using `read_csv` seperated by `\\t`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third dataset uses the Tweepy library to query additional data via the Twitter API (tweet_json.txt)\n",
    "\n",
    "*Note:* Tweepy library was not used for the project due to the mobile verification issues when creating twitter developer account. Instead, I download the `tweet_json.txt` provided by Udacity instructor to read the file by line line in a pandas dataframe with minimum columns of tweet id, retweet counts and favorite counts.\n",
    "\n",
    "- Import tweepy library.\n",
    "- Query Twitter API for each tweet in the Twitter archive and save JSON in a text file.\n",
    "- Created an empty dictionary `tweets_list`.\n",
    "- Use open file method to read the file `tweet-json.txt` line ny line.\n",
    "- Use Json_loads to convert the json object strings line to python dictionary and access its values.\n",
    "- Append `tweet_id`,`retweet_count`,`favorite_count` tp the `tweets_list` created earlier.\n",
    "- Convert the `tweet list` to dataframe `tweets_counts`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this section, detected eight (8) quality issues and two (2) tidiness issues using both visual and programmatic assessment to assess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use visual assessment by scanning through or scrolling to detect any quality and tidiness issues in the three datasets.\n",
    "- Use programmatic assessment by getting the datasets info / describe (summary statistics) to detect any quality and tidiness issues in the three datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality issues\n",
    "\n",
    "The eight (8) quality issues are:\n",
    "\n",
    "1. `tweets archive table` - Remove all retweets.\n",
    "\n",
    "2. `tweets archive table` - drop in reply to status id, in reply to user id, retweeted status id, retweeted status user id, retweeted status timestamp column (missing data).\n",
    "\n",
    "3. Extract url content from source column.\n",
    "\n",
    "4. Extract text url content form the text column.\n",
    "\n",
    "5. Erroneous datatype assigned to timestamp column.\n",
    "\n",
    "6. Extract data and time from timestamp column.\n",
    "\n",
    "7. Inaccurate rating denominator (not exactly 10 - greater/less than).\n",
    "\n",
    "8. Invalid names in the name column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness issues\n",
    "\n",
    "The two (2) tidiness issues are:\n",
    "\n",
    "1. `tweets archive table` - Clubbing 4 dog stage columns into 1 column\n",
    "\n",
    "2. Merged all the three (3) datasets into one (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this section, all the quality and tidiness issues during assessment are cleaned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, make a copy of the three datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data issues are cleaned for completeness before any other issues:\n",
    "- `tweets archive table`: Remove all retweets.\n",
    "- `tweets archive table` : Drop in reply to status id, in reply to user id, retweeted status id, retweeted status user id, retweeted status timestamp column (missing data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tidiness data issues are cleaned to follow the rules; \n",
    "- Each variable form a column.\n",
    "- Each observation form a row.\n",
    "- Each type of observational unit form a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality data issues are cleaned for analyzing and visualizing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data wrangling, the cleaned master dataset saved to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle_report.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
